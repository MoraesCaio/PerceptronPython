{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import spline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "Perceptron é um classificador binário linear e representa um neurônio, a estrutura básica de uma rede neural. No perceptron, recebe-se os atributos de entrada da base de treinamento (e.g. as entradas de uma porta lógica AND/OR) e multiplica, cada uma delas, por um peso W, conforme Figura 1. Feito isso, os valores resultantes são somados e passam por uma função de ativação.\n",
    "Nesse notebook, todos os passos para implementação do perceptron serão feitos utilizando Numpy, para isso, 5 etapas deverão ser feitas:\n",
    "1. Inicializaçao dos pesos e bias\n",
    "2. Implementando funções de ativação\n",
    "3. Calculando a saída do neurônio\n",
    "4. Predição\n",
    "5. Treino e avaliação\n",
    "\n",
    "![alt text](imgs/perceptron.jpg \"Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 1 - Inicialização dos pesos e bias\n",
    "\n",
    "Ao implementar um perceptron, o primeiro passo é iniciar os pesos em um intervalo pequeno, como [-0.5,0.5] aleatoriamente. O bias quando necessário também deve ser inicializado nessa etapa.\n",
    "\n",
    "Para implementar essa etapa, voçê deve utilizar a função weight_init(num_inputs). Dica: você pode utilizar a [função random do numpy](https://docs.scipy.org/doc/numpy/reference/generated/numpy.random.random.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w: [0.27122333 0.56513091 0.24401206 0.17750054 0.47948265 0.05057883\n",
      " 0.30271898 0.07135345 0.87679336 0.46075505]\n",
      "b: -0.1\n"
     ]
    }
   ],
   "source": [
    "def weight_init(num_inputs): \n",
    "    \"\"\"\n",
    "    Funcao que inicializa os pesos e bias aleatoriamente utilizando numpy\n",
    "    Parametro: num_inputs - quantidade de entradas X\n",
    "    Retorna: w,b - pesos e bias da rede inicializados\n",
    "    \"\"\"\n",
    "    ### Insira seu código aqui (~2 linhas)\n",
    "    w = np.random.random((num_inputs))\n",
    "    b = -0.1\n",
    "    return w, b\n",
    "\n",
    "# test\n",
    "w, b = weight_init(10)\n",
    "print(\"w: \" + str(w))\n",
    "print(\"b: \" + str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 2 - Implementação das funções de ativação\n",
    "As funções de ativação definem o intervalo de valores que a saída do neurônio poderá ter. Para redes neurais tradicionais, utiliza-se as funções degrau e sigmoid. Redes neurais profundas podem utilizar as funções ReLU, LeakyReLU e Tangente Hiperbólica para evitar problemas no gradiente.\n",
    "\n",
    "Nsse Notebook, as quatro funções de ativação devem ser implementadas, para verificar a corretude das mesmas, a função visualizeActivationFunc exibe os gráficos correspondentes, as funçoes, suas respectivas saídas e gráfico deverão ser similares ao exposto abaixo: (Dica: utilize a [função exp](https://docs.scipy.org/doc/numpy/reference/generated/numpy.exp.html) do numpy)\n",
    "* Degrau: saída 0 se menor que 0 e saída 1 caso contrário\n",
    "$$ \\begin{equation}\n",
    "  degrau =\\begin{cases}\n",
    "    1, & \\text{se $x>0$}.\\\\\n",
    "    0, & \\text{caso contrário}.\n",
    "  \\end{cases}\n",
    "\\end{equation} $$\n",
    "![alt text](imgs/degrau.png \"Title\")\n",
    "* Sigmoid: saída entre [0,1]\n",
    "$$ \\begin{equation}\n",
    "  sigmoid = \\frac{1}{1 + e^{-z}}\n",
    "\\end{equation} $$\n",
    "![alt text](imgs/sigmoid.png \"Title\")\n",
    "* Retificadora (Relu): saída 0 caso entrada seja negativa e maior que 1 caso contrário\n",
    "$$ \\begin{equation}\n",
    "  relu = max(0,x)\n",
    "\\end{equation} $$\n",
    "![alt text](imgs/relu.png \"Title\")\n",
    "* Tangente Hiperbólica: saída entre [-1,1]\n",
    "$$ \\begin{equation}\n",
    "  tanh = \\frac{2}{(1+e^{-2*z})} - 1\n",
    "\\end{equation} $$\n",
    "![alt text](imgs/tanh.png \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SIGMOID\n",
      "[0.11920292 0.13010847 0.14185106 0.15446527 0.16798161 0.18242552\n",
      " 0.19781611 0.21416502 0.23147522 0.24973989 0.26894142 0.2890505\n",
      " 0.31002552 0.33181223 0.35434369 0.37754067 0.40131234 0.42555748\n",
      " 0.450166   0.47502081 0.5        0.52497919 0.549834   0.57444252\n",
      " 0.59868766 0.62245933 0.64565631 0.66818777 0.68997448 0.7109495\n",
      " 0.73105858 0.75026011 0.76852478 0.78583498 0.80218389 0.81757448\n",
      " 0.83201839 0.84553473 0.85814894 0.86989153 0.88079708]\n",
      "\n",
      "SOLO SIGMOID\n",
      "0.11920292202211755\n",
      "\n",
      "TANH\n",
      "[-0.96402758 -0.95623746 -0.94680601 -0.93540907 -0.92166855 -0.90514825\n",
      " -0.88535165 -0.86172316 -0.83365461 -0.80049902 -0.76159416 -0.71629787\n",
      " -0.66403677 -0.60436778 -0.53704957 -0.46211716 -0.37994896 -0.29131261\n",
      " -0.19737532 -0.09966799  0.          0.09966799  0.19737532  0.29131261\n",
      "  0.37994896  0.46211716  0.53704957  0.60436778  0.66403677  0.71629787\n",
      "  0.76159416  0.80049902  0.83365461  0.86172316  0.88535165  0.90514825\n",
      "  0.92166855  0.93540907  0.94680601  0.95623746  0.96402758]\n",
      "\n",
      "SOLO TANH\n",
      "-0.9640275800758169\n",
      "\n",
      "RELU\n",
      "[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      " 0.  0.  0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.  1.1 1.2 1.3 1.4 1.5\n",
      " 1.6 1.7 1.8 1.9 2. ]\n",
      "\n",
      "SOLO RELU\n",
      "0.0\n",
      "\n",
      "DEGRAU\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1]\n",
      "\n",
      "SOLO DEGRAU\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def activation_func(func_type, z):\n",
    "    \"\"\"\n",
    "    Funcao que implementa as funcoes de ativacao mais comuns\n",
    "    Parametros: func_type - uma string que contem a funcao de ativacao desejada\n",
    "                z - vetor com os valores de entrada X multiplicado pelos pesos\n",
    "    Retorna: saida da funcao de ativacao\n",
    "    \"\"\"\n",
    "    z = np.asarray(z)\n",
    "    # Seu codigo aqui (~2 linhas)\n",
    "    if func_type == 'sigmoid':\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    elif func_type == 'tanh':\n",
    "        return (2 / (1 + np.exp(-2 * z))) - 1\n",
    "    elif func_type == 'relu':\n",
    "        return np.maximum(0, z)\n",
    "    elif func_type == 'degrau':\n",
    "        return 1 * (z > 0)\n",
    "\n",
    "\n",
    "# test\n",
    "p = [x/10.0 for x in range(-20, 21)]\n",
    "print(\"\\nSIGMOID\\n\" + str(activation_func('sigmoid', p)))\n",
    "print(\"\\nSOLO SIGMOID\\n\" + str(activation_func('sigmoid', p[0])))\n",
    "print(\"\\nTANH\\n\" + str(activation_func('tanh', p)))\n",
    "print(\"\\nSOLO TANH\\n\" + str(activation_func('tanh', p[0])))\n",
    "print(\"\\nRELU\\n\" + str(activation_func('relu', p)))\n",
    "print(\"\\nSOLO RELU\\n\" + str(activation_func('relu', p[0])))\n",
    "print(\"\\nDEGRAU\\n\" + str(activation_func('degrau', p)))\n",
    "print(\"\\nSOLO DEGRAU\\n\" + str(activation_func('degrau', 0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f67957fea50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualizeActivationFunc(z):\n",
    "    func = []\n",
    "    for i in range(len(z)):\n",
    "        func.append(activation_func('tanh', z[i]))\n",
    "\n",
    "    plt.plot(z,func)\n",
    "    plt.xlabel('Entrada')\n",
    "    plt.ylabel('Valores de Saida')\n",
    "    plt.show()\n",
    "\n",
    "z = np.arange(-5., 5., 0.2)\n",
    "visualizeActivationFunc(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 3 - Cálculo da saída do neurônio¶\n",
    "\n",
    "Com os pesos, bias inicializados e a função de ativação implementada, calcula-se a saída através da equação:\n",
    "\n",
    " $$ \\begin{equation}\n",
    "  Z = W*X + b\n",
    "\\end{equation} $$\n",
    "Feito isso, a saída final é calculada a partir da função de ativação escolhida. Para implementar essa função, você pode utilizar a [função dot do numpy](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html) para multiplicar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(w,b,X):\n",
    "    \"\"\"\n",
    "    Funcao que implementa a etapa forward propagate do neurnio\n",
    "    Parametros: w - pesos\n",
    "                b - bias\n",
    "                X - entradas\n",
    "    \"\"\"\n",
    "    ### Seu codigo aqui (~2 linhas)\n",
    "    z = np.dot(w, X) + b\n",
    "    return activation_func('sigmoid', z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 4 - Predição\n",
    "De posse da saída, deve-se avaliar o sucesso da mesma definindo-se um limiar. Para problemas binários, pode-se estabelecer o limiar em 0.5, de forma que abaixo disso a saída é 0 e 1 caso contrário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(out):\n",
    "    \"\"\"\n",
    "    Funcao que aplica um limiar na saida\n",
    "    Parametro: y - saida do neuronio\n",
    "    \"\"\"\n",
    "    ### Seu codigo aqui (~1 linha)\n",
    "    return 1 * (out >= 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 5 - Treino e Avaliação\n",
    "\n",
    "Durante o treinamento, a saída é calculada pela função propagate n vezes, onde n é a quantidade de interações do algoritmo. Na primeira interação, os pesos possuem valores pré-definidos pela função de inicialização e são aleatórios após essa interação, as próximas calculam o peso baseado em um erro, calculado a partir da equação:\n",
    "\n",
    " $$ \\begin{equation}\n",
    "  erro = y - ypred\n",
    "\\end{equation} $$\n",
    "\n",
    "Onde y é a saída original do conjunto de dados e y_pred as saidas calculadas. Dado o erro, os pesos são atualizados a partir da equação:\n",
    "\n",
    "$$ \\begin{equation}\n",
    "  w += erro*taxa-de-aprendizado*X\n",
    "\\end{equation} $$\n",
    "\n",
    " \n",
    "Onde X é o conjunto de entrada e a taxa de aprendizagem é um parâmetro de otimização que possui seus valorse variando entre [0,1]. Recomenda-se o uso de taxas de aprendizagem medianas para problemas com redes neurais tradicionais simples (como 0.2-0.5) e taxas de aprendizagem menores para redes neurais profundas (acima de 0.02)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(x,y, num_interaction, learning_rate):\n",
    "    \"\"\"\n",
    "    Funcao que implementa o loop do treinamento \n",
    "    Parâmetros: x - entrada da rede \n",
    "                y - rotulos/labels\n",
    "                num_interaction - quantidade de interacoes desejada para a rede convergir\n",
    "                learning_rate - taxa de aprendizado para calculo do erro\n",
    "    \"\"\"\n",
    "    #Passo 1 - Inicie os pesos e bias (~1 linha)\n",
    "    w, b = weight_init(x.shape[0])\n",
    "    #Passo 2 - Loop por X interacoes\n",
    "    for j in range(None):\n",
    "        # Passo 3 -  calcule a saida do neuronio (~1 linha)\n",
    "        y_pred = forward(w, b, x)\n",
    "        # Passo 4 - calcule o erro entre a saida obtida e a saida desejada nos rotulos/labels (~1 linha)\n",
    "        erro = y - y_pred\n",
    "        # Passo 5 - Atualize o valor dos pesos (~1 linha)\n",
    "        # Dica: voce pode utilizar a funcao np.dot e a funcao transpose de numpy \n",
    "        w += np.dot(erro*learning_rate, x.T)\n",
    "        \n",
    "    # Verifique as saídas\n",
    "    print('Saída obtida:', y_pred)\n",
    "    print('Pesos obtidos:', w)\n",
    "\n",
    "    #Métricas de Avaliação\n",
    "    y_pred = predict(y_pred)\n",
    "    print('Matriz de Confusão:')\n",
    "    print(confusion_matrix(y, y_pred))\n",
    "    print('F1 Score:')\n",
    "    print(classification_report(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
